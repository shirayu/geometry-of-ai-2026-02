# 第8回：時間の発見 ～一撃からの脱却～

## 注意事項

- 残差接続を「多様体上の流れ」と見る解釈は、連続時間極限での比喩的理解であり、実際のResNetは離散的なステップである。
- Neural ODEの連続時間解釈は理論的に厳密だが、実装上は離散化が必要であり、計算コストと精度のトレードオフがある。
- 「空間が安定すると時間発展が扱える」は経験的観察であり、理論的保証ではない。
- 本回で扱う「時間」は、物理的な時間ではなく、生成や推論の「プロセスの進行度」を指す。

## 導入：召喚術から映画制作へ

これまでの講義では、表現空間の「形」を議論してきた。球面、双曲空間、分布としての埋め込み。しかし、これらはすべて**静的な描像**である。星空のスナップショットは撮れるが、星の動きを追うことはできない。

深層学習の歴史を振り返ると、興味深い転換点がある。初期の生成モデル（GAN、VAE）は、潜在空間から出力空間への**一撃の変換**を行っていた。魔法使いが呪文を唱えると、何もないところから画像が「召喚」される。中間過程は見えない。

しかし、近年の主流は異なる。拡散モデルは、ノイズから徐々に意味が立ち上がる**プロセス**を明示的に扱う。Chain of Thoughtは、推論の過程を**軌跡のように見える形で**言語化する。なぜ、このパラダイムシフトが起きたのか。

> [!NOTE]
> **Chain of Thoughtと「軌跡」：** Chain of Thoughtが出力するのはテキスト列であり、モデル内部の連続状態の軌道そのものではない。また、出力されたテキストがモデル内部で実際に行われた計算を完全に反映するとは限らない。しかし、「中間過程を明示的に表現する」という点で、一撃変換からの脱却という文脈では類似の方向性を持つ。

本回では、この「時間の発見」を幾何学的に探求する。鍵となるのは、**空間の安定化**が**時間発展の制御**を可能にしたと解釈できるという洞察である。

## 古典的生成モデル：一撃の召喚術

### GANの構造

**GAN（Generative Adversarial Network）**（Goodfellow et al., 2014）は、生成モデルの革命だった。その構造は驚くほどシンプルである。

```txt
潜在ベクトル z ∈ ℝ^d → 生成器 G → 画像 x ∈ ℝ^{H×W×C}
```

潜在空間からサンプリングされた $\mathbf{z}$ が、ニューラルネットワーク $G$ を一度通過するだけで、高次元の画像が生成される。識別器 $D$ との敵対的学習により、 $G$ は「本物らしい」画像を生成するよう訓練される。

| 要素 | 役割 |
| --- | --- |
| 潜在ベクトル $\mathbf{z}$ | ランダムな「種」 |
| 生成器 $G$ | 種を画像に変換する「召喚術」 |
| 識別器 $D$ | 本物と偽物を見分ける「審判」 |

### VAEの構造

**VAE（Variational Autoencoder）**（Kingma & Welling, 2014）は、確率的な枠組みを導入した。

```txt
入力 x → エンコーダ → 潜在分布 q(z|x) → サンプリング → デコーダ → 再構成 x̂
```

エンコーダは入力を潜在分布のパラメータ（平均と分散）に変換し、そこからサンプリングした $\mathbf{z}$ をデコーダが再構成する。KLダイバージェンスによる正則化が、潜在空間の構造を整える。

### 一撃変換の限界

これらのモデルは画期的だったが、共通の限界を持っていた。

**中間過程の不可視性**： $\mathbf{z}$ から $\mathbf{x}$ への変換は、ブラックボックスの中で一気に起こる。途中で「どこまで生成が進んだか」を確認したり、「この方向に修正したい」と介入したりすることが難しい。

**学習の不安定性**：特にGANは、生成器と識別器のバランスが崩れやすく、モード崩壊（特定のパターンしか生成しなくなる）や学習の発散が頻繁に起きた。

**制御の困難さ**：「目を少し大きく」「背景を変えて」といった細かい制御が難しい。潜在空間の構造が不明瞭で、どの方向に動けば何が変わるかが分からない。

> [!NOTE]
> **GANの改良の歴史：** GANの不安定性に対しては、多くの改良が提案された。DCGAN（畳み込みの導入）、WGAN（Wasserstein距離）、StyleGAN（スタイルベースの生成）など。これらの改良は、暗黙的に「空間の安定化」と「プロセスの制御」を追求していたと見ることもできる。

## 不安定性の幾何学的理解

### ノルムの暴走

第2回で議論したように、正規化されていない空間では、ベクトルのノルムが学習中に暴走しやすい。

生成器の中間層で $\|\mathbf{h}\|$ が爆発すると：

- 勾配も爆発し、学習が発散する
- 活性化関数が飽和し、勾配が消失する
- 出力が極端な値に偏り、多様性が失われる

このノルムの不安定性は、「滑らかな軌道」を描くことを困難にする。

### 軌道としての生成

生成を「潜在空間から出力空間への軌道」として捉えてみよう。

理想的には、 $\mathbf{z}$ から $\mathbf{x}$ への変換は、何らかの多様体上の滑らかな曲線であってほしい。しかし、ノルムが暴れる空間では、この曲線がギザギザになったり、突然ジャンプしたりする。

| 空間の状態 | 軌道の性質 | 結果 |
| --- | --- | --- |
| 不安定（ノルム暴走） | ギザギザ、不連続 | 学習困難、制御不能 |
| 安定（正規化済み） | 滑らか、連続 | 学習容易、制御可能 |

> [!IMPORTANT]
> **因果関係の注意：** 「空間の安定化」→「軌道の制御可能性」という関係は、経験的に観察されるパターンであり、厳密な数学的定理ではない。実際には、アーキテクチャ、損失関数、最適化手法など、複数の要因が絡み合っている。

## 転換点：安定化技術の成熟

### 残差接続（ResNet）

**残差接続**（He et al., 2016）は、深層学習の安定性を劇的に改善した。

$$\mathbf{h}_{t+1} = \mathbf{h}_t + f(\mathbf{h}_t)$$

従来の理解では、これは「勾配消失問題の緩和」として説明される。スキップ接続により、勾配が直接浅い層に伝播できる。

しかし、幾何学的には別の解釈も可能である。

### 残差接続の幾何学的再解釈

残差接続を、**多様体上の流れの離散近似**として読み直そう。

- $\mathbf{h}_t$ ：現在の状態（多様体上の点）
- $f(\mathbf{h}_t)$ ：接空間上のベクトル場（「どの方向に動くべきか」）
- $\mathbf{h}_{t+1} = \mathbf{h}_t + f(\mathbf{h}_t)$ ：オイラー法による1ステップの更新

この見方では、ResNetの各層は「時間」の1ステップに対応する。層を深くすることは、時間を長く進めることに相当する。

```txt
層1 → 層2 → 層3 → ... → 層L
 ↓      ↓      ↓           ↓
t=0 → t=1 → t=2 → ... → t=L
```

> [!NOTE]
> **比喩の限界：** この「時間」は物理的な時間ではなく、計算の「深さ」を時間軸に見立てた比喩である。実際のResNetは離散的であり、連続時間のODEとは異なる。しかし、この比喩はNeural ODEへの橋渡しとして有用である。

### スキップ接続の役割

スキップ接続 $\mathbf{h}_{t+1} = \mathbf{h}_t + f(\mathbf{h}_t)$ において、 $\mathbf{h}_t$ の項は何を意味するか。

**記憶保持機構**：入力の情報を、変換を経ても保持する。 $f(\mathbf{h}_t)$ が何をしようと、 $\mathbf{h}_t$ の成分は残る。

**恒等写像への近さ**： $f(\mathbf{h}_t) \approx 0$ のとき、 $\mathbf{h} _{t+1} \approx \mathbf{h}_t$ となる。つまり、「何もしない」という選択肢が常にある。これにより、深い層でも浅い層の情報が失われにくい。

**安定性の源**： $f$ の出力が小さければ、状態の変化も小さい。これが、深いネットワークでも学習を安定させる一因となる。

### 正規化層の役割

残差接続と並んで重要なのが、**正規化層**である。

**Batch Normalization**（Ioffe & Szegedy, 2015）：ミニバッチ内で平均・分散を正規化。

**Layer Normalization**（Ba et al., 2016）：各サンプル内で正規化。Transformerで広く使用。

**RMSNorm**（Zhang & Sennrich, 2019）：平均を引かず、二乗平均平方根で割る。LLMで採用例多数。

これらの正規化は、活性化のスケールを一定範囲に保つ。ノルムの暴走を防ぎ、空間を「安定」させる。

| 正規化手法 | 正規化の軸 | 主な用途 |
| --- | --- | --- |
| Batch Norm | バッチ方向 | CNN |
| Layer Norm | 特徴方向 | Transformer |
| RMSNorm | 特徴方向（平均なし） | 大規模LLM |

> [!CAUTION]
> **LayerNormとL2正規化の違い：** 第6回でも強調したが、LayerNorm/RMSNormは平均・分散の正規化であり、ベクトルを単位ノルムにするL2正規化とは異なる。LayerNormを通過したベクトルは、一般に単位ノルムではない。

## Neural ODE：連続時間への拡張

### 離散から連続へ

ResNetの残差接続を、時間ステップ $\Delta t = 1$ のオイラー法と見なすと：

$$\mathbf{h}_{t+\Delta t} = \mathbf{h}_t + \Delta t \cdot f(\mathbf{h}_t)$$

$\Delta t \to 0$ の極限を取ると、常微分方程式（ODE）が得られる：

$$\frac{d\mathbf{h}}{dt} = f(\mathbf{h}, t, \theta)$$

**Neural ODE**（Chen et al., 2018）は、この連続時間の枠組みを直接扱う。

### Neural ODEの利点

**メモリ効率（理論上）**：順伝播で中間状態を保存する必要がない。逆伝播は「随伴法（adjoint method）」により、随伴方程式を解くことで計算できる（実装では逆時間方向での数値積分や再計算を伴う）。

> [!NOTE]
> **実運用上のトレードオフ：** 随伴法は「中間状態を全保存しない」設計が可能という意味でメモリ効率が良い。ただし、以下の問題がある：
>
> - **数値的不安定性**：随伴法は逆時間方向にODEを解くため、順方向で安定だった軌道が逆方向では不安定（発散しやすい）になることがある
> - **誤差の蓄積**：逆向き積分中の数値誤差が勾配の精度を低下させる
> - **チェックポイント併用**：安定性のため、結局中間状態を一部保存するケースも多い
>
> 実務では、メモリを消費しても**通常の逆伝播（Backprop through time）の方が精度が出る**場合がある。メモリと精度のトレードオフを考慮して手法を選択する必要がある。

**適応的な計算**：数値積分器（Runge-Kutta法など）が、精度に応じてステップ数を自動調整する。ベクトル場が急峻な領域や剛性（stiffness）が高い軌道では、誤差制御のためにステップ数が増加する。逆に、滑らかな領域では少ないステップで済む。

**連続的な深さ**：層の数が離散的ではなく、連続的な「時間」として扱える。これにより、任意の精度で計算を停止できる。

### Neural ODEの構造

```txt
入力 h(0) → ODEソルバー [ dh/dt = f(h,t,θ) ] → 出力 h(T)
              ↑
         ニューラルネット f
```

$f$ はニューラルネットワークで表現され、 $\theta$ はその学習パラメータ。ODEソルバーが、 $t=0$ から $t=T$ まで状態を積分する。

### Neural ODEの表現力の限界とAugmented Neural ODEs

Neural ODEには重要な制約がある。ODEの解は連続で、異なる初期条件から出発した軌道は交差しない（解の一意性）。これは、**トポロジー的に表現できない関数が存在する**ことを意味する。

典型的な例は、同心円状に配置された2クラスの分類問題である。内側の円と外側の円を分離するには、軌道が「交差」する必要があるが、ODEではこれができない。

```txt
    外側クラス: ○ ○ ○
              ○     ○
    内側クラス:   ● ●
              ○  ●  ○
              ○     ○
              ○ ○ ○
```

**Augmented Neural ODEs**（Dupont et al., 2019）は、この制約を回避するために**状態空間の次元を拡張**する。入力を高次元空間に持ち上げることで、元の空間では交差するように見える軌道も、拡張された空間では交差しないように配置できる。

$$\mathbf{h}_{\text{aug}} = [\mathbf{h}, \mathbf{0}] \in \mathbb{R}^{d + d'}$$

これは、2次元で結び目を解くには3次元が必要、という直感と同じである。

> [!NOTE]
> **計算コストのトレードオフ：** Neural ODEはメモリ効率が良いが、計算時間は増加しうる。特に、 $f$ の評価回数（ODEソルバーのステップ数）が多くなると、標準的なResNetより遅くなる場合がある。

## 時間発展の幾何学

### 位相空間としての表現空間

力学系の言葉を借りると、表現空間は**位相空間（phase space）**に対応する。各点が「状態」を表し、時間発展は位相空間内の軌道として描かれる。

生成モデルの文脈では：

- **位相空間**：潜在空間 + 中間表現の空間
- **軌道**：生成プロセスにおける状態の遷移
- **アトラクター**：学習されたデータ分布

### ベクトル場としてのニューラルネットワーク

Neural ODEの $f(\mathbf{h}, t, \theta)$ は、位相空間上の**ベクトル場**を定義する。各点 $\mathbf{h}$ に対して、「次にどの方向に動くべきか」を指示する矢印が割り当てられている。

学習とは、このベクトル場を調整して、望ましい軌道（例：ノイズからデータへの変換）を実現することである。

```txt
      ↗ → →
    ↗   ↘
  ↗       ↓   ← ベクトル場
  ↑       ↓
  ↑     ↙
    ← ← ←
```

### 流れの保存則

連続時間の流れには、重要な性質がある。ODEの解は、初期条件が近ければ、（少なくとも短時間では）近くを通る。これは**連続依存性**と呼ばれる。

この性質により、潜在空間での「近さ」が、生成結果の「近さ」に反映されやすくなる。 $\mathbf{z}_1$ と $\mathbf{z}_2$ が近ければ、生成される $\mathbf{x}_1$ と $\mathbf{x}_2$ も近い。

> [!IMPORTANT]
> **カオスの可能性：** ただし、長時間の発展では、初期条件のわずかな違いが大きな差を生む「カオス」が起こりうる。Neural ODEがカオス的になるかどうかは、ベクトル場 $f$ の性質に依存する。

## 拡散モデルへの橋渡し

### 拡散モデルの直感

**拡散モデル**（次回詳述）は、Neural ODEの考え方をさらに発展させたものである。

基本的なアイデア：

1. データにノイズを徐々に加えて、完全なノイズにする（順過程）
2. このノイズ付加過程を逆転させる方法を学習する（逆過程）
3. ランダムノイズから始めて、逆過程を適用すると、データが生成される

```txt
データ x₀ → x₁ → x₂ → ... → xₜ → 純粋ノイズ
  ↑                               |
  └──── 学習した逆過程で戻る ─────┘
```

### なぜ拡散モデルが強力か

**中間過程の可視性**：生成の各ステップが明示的に定義されている。 $t=T$ から $t=0$ への軌跡を追跡できる。

**学習の安定性**：各ステップで「ノイズを少し除去する」というシンプルなタスクを学習する。GAN のような敵対的学習の不安定性がない。

**制御の容易さ**：中間状態に介入することで、生成を制御できる。Classifier-free guidanceなどの技術が、この性質を活用している。

### 時間の明示化

拡散モデルでは、「時間」 $t$ が明示的なパラメータとして現れる。モデルは $(\mathbf{x}_t, t)$ を入力として受け取り、「時刻 $t$ での状態 $\mathbf{x}_t$ から、どの方向に進むべきか」を出力する。

この構造はNeural ODEのベクトル場 $f(\mathbf{h}, t, \theta)$ と類似している。ただし、拡散モデルの本質は**確率過程（SDE：確率微分方程式）**であり、ODEではない点に注意が必要である。

> [!NOTE]
> **ODEとSDEの関係：** 拡散モデルには「確率流ODE（probability flow ODE）」というODE表現も存在し、これを使えば決定論的なサンプリングが可能になる。しかし、学習と生成の基本的な理解はSDE、または離散時間マルコフ連鎖（DDPM等における離散化された順過程・逆過程）に基づく。次回でこの関係を詳しく扱う。

## 実装ノート

> [!NOTE]
> 以下のコードは PyTorch >= 1.9 を前提とする。Neural ODEの実装には `torchdiffeq` ライブラリを使用する例も示す。

### 残差ブロックの実装

<details>
<summary>コード例: 08_residual_block.py</summary>

```08_residual_block.py
import torch
import torch.nn as nn


class ResidualBlock(nn.Module):
    """基本的な残差ブロック

    h_{t+1} = h_t + f(h_t)

    ここで f は2層のMLPとする。
    """

    def __init__(self, dim, hidden_dim=None):
        super().__init__()
        hidden_dim = hidden_dim or dim * 4

        self.net = nn.Sequential(
            nn.LayerNorm(dim),
            nn.Linear(dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, dim),
        )

        # 出力を小さく初期化（学習初期の安定性のため）
        nn.init.zeros_(self.net[-1].weight)
        nn.init.zeros_(self.net[-1].bias)

    def forward(self, x):
        # 残差接続: x + f(x)
        return x + self.net(x)


class ResidualStack(nn.Module):
    """残差ブロックを積み重ねたネットワーク

    「深さ」を「時間」として解釈できる。
    """

    def __init__(self, dim, num_blocks, hidden_dim=None):
        super().__init__()
        self.blocks = nn.ModuleList([ResidualBlock(dim, hidden_dim) for _ in range(num_blocks)])

    def forward(self, x, return_trajectory=False):
        """
        Args:
            x: 入力 [batch, dim]
            return_trajectory: Trueなら中間状態も返す

        Returns:
            output: 出力 [batch, dim]
            trajectory: (オプション) 軌跡 [num_blocks+1, batch, dim]
        """
        if return_trajectory:
            trajectory = [x]

        for block in self.blocks:
            x = block(x)
            if return_trajectory:
                trajectory.append(x)

        if return_trajectory:
            return x, torch.stack(trajectory)
        return x


# 使用例
dim, num_blocks = 64, 8
model = ResidualStack(dim, num_blocks)

x = torch.randn(32, dim)  # バッチサイズ32
output, trajectory = model(x, return_trajectory=True)

print(f"Input shape: {x.shape}")
print(f"Output shape: {output.shape}")
print(f"Trajectory shape: {trajectory.shape}")  # [9, 32, 64]
```

</details>

### Neural ODEの実装（torchdiffeqを使用）

<details>
<summary>コード例: 08_neural_ode.py</summary>

```08_neural_ode.py
# pip install torchdiffeq
import torch
import torch.nn as nn

try:
    from torchdiffeq import odeint

    TORCHDIFFEQ_AVAILABLE = True
except ImportError:
    TORCHDIFFEQ_AVAILABLE = False
    print("torchdiffeq not installed. Neural ODE examples will be skipped.")


class ODEFunc(nn.Module):
    """ODEの右辺 f(h, t) を定義するニューラルネットワーク

    dh/dt = f(h, t)
    """

    def __init__(self, dim, hidden_dim=None):
        super().__init__()
        hidden_dim = hidden_dim or dim * 4

        self.net = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.Tanh(),  # 有界な活性化関数（滑らかさの促進に寄与しうるが、
            # これだけでリプシッツ連続性が保証されるわけではない）
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, dim),
        )

    def forward(self, t, h):
        """
        Args:
            t: 時刻（スカラー）
            h: 状態 [batch, dim]

        Returns:
            dh/dt: 時間微分 [batch, dim]
        """
        # この実装ではtを使わない（自律系）
        # 時間依存にするなら、tを特徴として連結する
        return self.net(h)


class NeuralODE(nn.Module):
    """Neural ODEモデル"""

    def __init__(self, dim, hidden_dim=None):
        super().__init__()
        self.func = ODEFunc(dim, hidden_dim)

    def forward(self, x, t_span=None, method="dopri5", return_trajectory=False):
        """
        Args:
            x: 初期状態 h(0) [batch, dim]
            t_span: 積分する時刻のリスト（デフォルト: [0, 1]）
            method: ODEソルバー（'dopri5', 'euler', 'rk4'など）
            return_trajectory: Trueなら全時刻の状態を返す

        Returns:
            output: 最終状態 h(T) [batch, dim]
            trajectory: (オプション) 全時刻の状態 [len(t_span), batch, dim]
        """
        if not TORCHDIFFEQ_AVAILABLE:
            raise RuntimeError("torchdiffeq is required for Neural ODE")

        if t_span is None:
            t_span = torch.tensor([0.0, 1.0])

        # ODEを解く
        trajectory = odeint(self.func, x, t_span, method=method)

        if return_trajectory:
            return trajectory[-1], trajectory
        return trajectory[-1]


# 使用例（torchdiffeqがインストールされている場合）
if TORCHDIFFEQ_AVAILABLE:
    dim = 64
    model = NeuralODE(dim)

    x = torch.randn(32, dim)
    t_span = torch.linspace(0, 1, 11)  # 0, 0.1, 0.2, ..., 1.0

    output, trajectory = model(x, t_span, return_trajectory=True)

    print(f"Input shape: {x.shape}")
    print(f"Output shape: {output.shape}")
    print(f"Trajectory shape: {trajectory.shape}")  # [11, 32, 64]
```

</details>

### 軌跡の可視化

<details>
<summary>コード例: 08_trajectory_visualization.py</summary>

```08_trajectory_visualization.py
import matplotlib.pyplot as plt
import numpy as np
import torch


class ResidualStack:
    def __init__(self, dim, num_blocks):
        self.dim = dim
        self.num_blocks = num_blocks

    def __call__(self, x, return_trajectory=False):
        trajectory = x.unsqueeze(0).repeat(self.num_blocks + 1, 1, 1)
        if return_trajectory:
            return x, trajectory
        return x


def visualize_trajectory_2d(trajectory, title="State Trajectory"):
    """2次元に射影した軌跡を可視化

    Args:
        trajectory: 軌跡 [time_steps, batch, dim]
        title: グラフのタイトル
    """
    # 最初の2次元に射影
    traj_2d = trajectory[:, :, :2].detach().cpu().numpy()
    time_steps, batch_size, _ = traj_2d.shape

    fig, ax = plt.subplots(figsize=(8, 8))

    # 各サンプルの軌跡をプロット
    colors = plt.cm.viridis(np.linspace(0, 1, batch_size))

    for i in range(min(batch_size, 20)):  # 最大20サンプル
        ax.plot(traj_2d[:, i, 0], traj_2d[:, i, 1], color=colors[i], alpha=0.5, linewidth=1)
        ax.scatter(
            traj_2d[0, i, 0],
            traj_2d[0, i, 1],
            color=colors[i],
            marker="o",
            s=50,
            label="Start" if i == 0 else "",
        )
        ax.scatter(
            traj_2d[-1, i, 0],
            traj_2d[-1, i, 1],
            color=colors[i],
            marker="x",
            s=50,
            label="End" if i == 0 else "",
        )

    ax.set_xlabel("Dimension 1")
    ax.set_ylabel("Dimension 2")
    ax.set_title(title)
    ax.legend()
    ax.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig("trajectory_2d.png", dpi=150)
    plt.close()

    print("Saved: trajectory_2d.png")


# ResidualStackの軌跡を可視化
dim, num_blocks = 2, 20  # 2次元で直接可視化
model = ResidualStack(dim, num_blocks)

x = torch.randn(50, dim) * 2  # 50サンプル
output, trajectory = model(x, return_trajectory=True)

visualize_trajectory_2d(trajectory, "ResNet Trajectory (2D)")
```

</details>

### ResNetとNeural ODEの比較

<details>
<summary>コード例: 08_resnet_vs_ode.py</summary>

```08_resnet_vs_ode.py
import torch

TORCHDIFFEQ_AVAILABLE = False


class ResidualStack:
    def __init__(self, dim, num_steps):
        self.dim = dim
        self.num_steps = num_steps

    def __call__(self, x, return_trajectory=False):
        trajectory = x.unsqueeze(0).repeat(self.num_steps + 1, 1, 1)
        if return_trajectory:
            return x, trajectory
        return x


class NeuralODE:
    def __init__(self, dim):
        self.dim = dim

    def __call__(self, x, t_span, return_trajectory=False):
        trajectory = x.unsqueeze(0).repeat(t_span.numel(), 1, 1)
        if return_trajectory:
            return x, trajectory
        return x


def compare_resnet_and_ode(dim=64, num_steps=10):
    """ResNetとNeural ODEの挙動を比較

    ResNet: 離散的なステップ
    Neural ODE: 連続的な流れ（離散化して比較）
    """
    # ResNet
    resnet = ResidualStack(dim, num_steps)

    # Neural ODE（利用可能な場合）
    if TORCHDIFFEQ_AVAILABLE:
        neural_ode = NeuralODE(dim)

    # テスト入力
    x = torch.randn(16, dim)

    # ResNetの軌跡
    _, resnet_traj = resnet(x, return_trajectory=True)

    results = {
        "resnet": {
            "trajectory_shape": resnet_traj.shape,
            "output_norm_mean": resnet_traj[-1].norm(dim=-1).mean().item(),
            "output_norm_std": resnet_traj[-1].norm(dim=-1).std().item(),
        }
    }

    # Neural ODEの軌跡（利用可能な場合）
    if TORCHDIFFEQ_AVAILABLE:
        t_span = torch.linspace(0, 1, num_steps + 1)
        _, ode_traj = neural_ode(x, t_span, return_trajectory=True)

        results["neural_ode"] = {
            "trajectory_shape": ode_traj.shape,
            "output_norm_mean": ode_traj[-1].norm(dim=-1).mean().item(),
            "output_norm_std": ode_traj[-1].norm(dim=-1).std().item(),
        }

    return results


# 比較実行
results = compare_resnet_and_ode()
print("Comparison Results:")
for model_name, metrics in results.items():
    print(f"\n{model_name}:")
    for k, v in metrics.items():
        print(f"  {k}: {v}")
```

</details>

## まとめ

| 概念 | 定義 | 本回での役割 |
| --- | --- | --- |
| **一撃変換** | 潜在空間から出力空間への直接的な写像 | 古典的生成モデルの特徴 |
| **残差接続** | $\mathbf{h}_{t+1} = \mathbf{h}_t + f(\mathbf{h}_t)$ | 時間発展の離散近似 |
| **Neural ODE** | $\frac{d\mathbf{h}}{dt} = f(\mathbf{h}, t)$ | 連続時間の深層学習 |
| **ベクトル場** | 各点に速度ベクトルを割り当てる関数 | 時間発展の方向を決定 |
| **軌跡** | 位相空間内での状態の遷移 | 生成プロセスの可視化 |

### 本回のポイント

深層学習における「時間の発見」は、二つの技術的進歩と関連している。

**空間の安定化**：正規化層（LayerNorm、RMSNorm）と残差接続により、表現空間が安定しやすくなった。ノルムの暴走が抑えられることで、滑らかな軌道を描ける土台ができたと解釈できる。ただし、これは経験的な観察であり、「安定化すれば必ず時間発展が制御可能になる」という理論的保証ではない。

**時間の明示化**：残差接続を「時間ステップ」として読み直すことで、離散的な層の積み重ねが、連続的な流れの近似として理解できるようになった。Neural ODEはこの視点を厳密化し、連続時間の枠組みを提供した。

この見方は、生成モデルのパラダイム変化を理解する一つのレンズを与える。一撃の「召喚術」から、徐々に形が立ち上がる「映画制作」へ。次回では、この「映画」の具体例として、拡散モデルとSDEを詳しく見ていく。

> **空間が安定すると、「映画（プロセス）」が撮れるようになる。**

## 参考文献

### 残差接続とResNet

- He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. *CVPR 2016*. arXiv: [arXiv:1512.03385](https://arxiv.org/abs/1512.03385).
    - ResNetの原論文。残差接続が深いネットワークの学習を可能にすることを示した。
- He, K., Zhang, X., Ren, S., & Sun, J. (2016). Identity Mappings in Deep Residual Networks. *ECCV 2016*. arXiv: [arXiv:1603.05027](https://arxiv.org/abs/1603.05027).
    - Pre-activation ResNetの提案。残差接続の設計についてさらに分析。

### 正規化層

- Ioffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. *ICML 2015*. arXiv: [arXiv:1502.03167](https://arxiv.org/abs/1502.03167).
    - Batch Normalizationの原論文。
- Ba, J. L., Kiros, J. R., & Hinton, G. E. (2016). Layer Normalization. *arXiv:1607.06450*. arXiv: [arXiv:1607.06450](https://arxiv.org/abs/1607.06450).
    - Layer Normalizationの原論文。Transformerで広く使用される。
- Zhang, B., & Sennrich, R. (2019). Root Mean Square Layer Normalization. *NeurIPS 2019*. arXiv: [arXiv:1910.07467](https://arxiv.org/abs/1910.07467).
    - RMSNormの原論文。大規模LLMで採用例が増加。

### Neural ODE

- Chen, R. T. Q., Rubanova, Y., Bettencourt, J., & Duvenaud, D. (2018). Neural Ordinary Differential Equations. *NeurIPS 2018*. arXiv: [arXiv:1806.07366](https://arxiv.org/abs/1806.07366).
    - Neural ODEの原論文。連続深度モデルと随伴法による効率的な学習を提案。
- Dupont, E., Doucet, A., & Teh, Y. W. (2019). Augmented Neural ODEs. *NeurIPS 2019*. arXiv: [arXiv:1904.01681](https://arxiv.org/abs/1904.01681).
    - Neural ODEの表現力の限界と、次元を拡張することによる解決策。

### 古典的生成モデル

- Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., & Bengio, Y. (2014). Generative Adversarial Nets. *NeurIPS 2014*. arXiv: [arXiv:1406.2661](https://arxiv.org/abs/1406.2661).
    - GANの原論文。敵対的学習による生成モデル。
- Kingma, D. P., & Welling, M. (2014). Auto-Encoding Variational Bayes. *ICLR 2014*. arXiv: [arXiv:1312.6114](https://arxiv.org/abs/1312.6114).
    - VAEの原論文。変分推論による生成モデル。

### 拡散モデル（次回への接続）

- Ho, J., Jain, A., & Abbeel, P. (2020). Denoising Diffusion Probabilistic Models. *NeurIPS 2020*. arXiv: [arXiv:2006.11239](https://arxiv.org/abs/2006.11239).
    - DDPMの原論文。次回で詳しく扱う。

## 次回予告

第9回「拡散と凝縮」では、拡散モデルとSDEの対応を詳しく見ていく。

本回で導入した「時間」の概念を、確率過程の枠組みで拡張する。ノイズから意味が立ち上がるプロセスを、熱力学的な「拡散」と「凝縮」の言葉で記述する。スコア関数、ランジュバン動力学、そしてflow matchingといった技術が、幾何学的にどう解釈できるかを探求する。
