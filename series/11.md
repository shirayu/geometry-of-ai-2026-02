# 第11回：感覚の統合 ～異種多様体の結婚～

## 注意事項

- CLIPの「同じ空間に整列」は、テキスト・画像の両エンコーダ出力が $L_2$ 正規化されている場合に $\cos$ 類似度が角度として解釈できる。
- 「統一多様体」は設計目標であり、実際に単一の滑らかな多様体になっている保証はない。
- コントラスト学習の「引力・斥力」は比喩的表現。

## トピック

マルチモーダル学習の幾何学

## 内容

- **なぜマルチモーダルが難しいのか？**
    - テキスト：離散的、順序依存、文法構造
    - 画像：連続的、空間依存、局所パターン
    - 音声：時系列、周波数特性
    - それぞれが**異なる多様体**に住んでいる
- **CLIPの革命:**
    - 「テキスト表現」と「画像表現」を**同じ空間に整列させる**（多くは正規化＋cos類似）
    - 対照学習（コントラスト学習）： $\mathcal{L} = -\log \frac{\exp(\text{sim}(\mathbf{t}, \mathbf{i})/\tau)}{\sum_{j} \exp(\text{sim}(\mathbf{t}, \mathbf{i}_j)/\tau)}$
    - $\text{sim}(\mathbf{t}, \mathbf{i}) = \cos\theta$ （※正規化が前提）
- **対照学習の幾何:**
    - **正例ペア:** 球面上で近くに配置（角度を小さく）
    - **負例ペア:** 球面上で遠くに配置（角度を大きく）
    - 球面上での「引力・斥力」のシミュレーションとして読める
- **統一多様体の問題点:**
    - モダリティ固有の構造が失われる可能性
    - 例：画像の空間的隣接関係、テキストの構文構造
    - 「無理やり同じドームに押し込む」ことの歪み
- **次世代への示唆:**
    - **多様体間の準同型写像（morphism）:**
        - 完全に統一するのではなく、「翻訳関数」を学習
        - テキスト多様体 ⇄ 画像多様体 の可逆的マッピング
    - **階層的な統合:**
        - 低レベル：モダリティ固有の特徴
        - 高レベル：抽象的な共通表現
- **具体例: ImageBind (Meta):**
    - 6つのモダリティを単一の埋め込み空間に
    - でも本当に「統一」されているのか、それとも「無理やり並べた」だけなのか？
- CLIPの限界とその後の展開についても述べる

## 問い

統一多様体は可能か、それとも複数の多様体を「橋渡し」すべきか？

## 実装ノート

- CLIP類似度: `torch.nn.functional.cosine_similarity(text_emb, image_emb, dim=-1)`
- コントラスト損失は対称化・バッチ設計が重要
