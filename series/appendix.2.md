
# Appendix 2: 多様体の純度問題: 幾何学がまだ解けていない課題

## 問題の所在

本編は「空間の形」を設計する言語を整えた。しかし、その空間に注ぎ込まれる**データの真偽**については、幾何学は沈黙している。

**問い：**
> 正規化や球面化によって「計算の形式」は安定した。
> では「データの内容」を幾何学的に選別できるか？

**結論を先取りすれば：**
> 現時点では**できない**。本Appendixはその理由と、将来の研究方向を地図として提示する。

**本Appendixにおける「純度」の定義：**
> 表現空間において、論理整合性・事実整合性に反するサンプルが、
> 学習分布にどれだけ**混入しているか**、および学習結果に**どれだけ影響を与えるか**。

- **混入率**：問題のあるサンプルの割合
- **影響度**：そのサンプル（またはクラスター）を除去・重み変更したときの、検証誤差・整合性テスト・推論安定性の変化量

混入率が低くても影響度が高い場合（例：頻出パターンに矛盾するデータ）、純度は低いと見なす。

## 本Appendixの射程

### 扱うこと

- 幾何学的安定化（表現空間の設計）と、データ選別（真偽判定）のギャップ
- 現行手法の幾何学的翻訳と、その限界
- 将来の研究方向（仮説レベル）

### 扱わないこと

- 特定アーキテクチャの批評（nGPT、GPT-4など）
- 社会制度論（誰がデータを管理すべきか）
- 最終的なアライメント論（何が「正しい」価値観か）

### 「正しさ」の3類型

本Appendixで「正しさ」という語を使う際、以下を区別する：

| 類型 | 定義 | 例 | 幾何学との関係 |
| ------ | ------ | ----- | --------------- |
| **論理整合性** | 推論規則に従っているか | A→B, B→C ならば A→C | 測地線の推移性？（未確立） |
| **事実整合性** | 観測・世界知識と一致するか | 1+1=2, 東京は日本の首都 | 外部参照が必要（幾何学単独では不可） |
| **規範整合性** | 価値判断として望ましいか | 公平性、安全性 | 幾何学の射程外 |

**注意：** 以下の議論は主に**論理整合性**と**事実整合性**に焦点を当てる。規範整合性は本質的に幾何学の外にある。

## 正規化が解決したこと・しなかったこと

[第3回「球面・正規化」](03.md)の限界について。

### 解決したこと（確立された効果）

| 問題 | 正規化による解決 | 幾何学的解釈 |
| ------ | ---------------- | ------------- |
| 学習の発散 | ノルムを一定に保つ | 球面上に拘束 |
| 収束の遅さ | 勾配のスケールが安定 | 曲率の均一化 |
| 表現の崩壊 | 方向のみで比較 | 角度空間への射影 |

### 解決しなかったこと（本質的な限界）

正規化は「ベクトルの方向」を揃えるが、「その方向が正しいか」は判断しない。

| 入力 | 正規化後 | 問題 |
| ------ | --------- | ------ |
| 「1+1=2」の埋め込み | 単位球面上の点 $\mathbf{v}_1$ | - |
| 「1+1=3」の埋め込み | 単位球面上の点 $\mathbf{v}_2$ | $\mathbf{v}_1$ と $\mathbf{v}_2$ の区別は**学習データの統計**に依存 |

**幾何学的に言えば：**
> 球面上に綺麗に配置されたデータが、全員「間違った方向」を指していても、モデルはそれを「正しい方向」として学習する。
> 正規化は「形式の安定」を与えるが、「内容の真偽」には中立である。

> [!NOTE]
> これは正規化の「欠陥」ではなく「設計上の射程」である。正規化に真偽判定を期待するのは、定規に善悪の判断を期待するようなものだ。

## 現行のデータ選別手法と幾何学的解釈

### 既存の道具を多様体の言葉で読み直す

| 手法 | 何をしているか | 測定量 | モデル依存性 | 幾何学的解釈 | 限界 |
| ------ | --------------- | -------- | ------------- | ------------- | ------ |
| **人手ラベリング** | 人間が「良い/悪い」を判定 | - | なし | 外部の神託 | スケールしない |
| **EL2Nスコア** | 予測誤差の大きいデータを選別 | **距離** | モデル・学習段階に依存 | 損失距離の代理 | 「難しい」と「間違い」の区別不能 |
| **Influence Functions** | 除去時の損失変化を逆算 | **曲率** | モデル・近似手法に依存 | Hessian近傍の寄与 | 計算コスト、近似の不安定さ |
| **kNN外れ値検出** | 近傍密度が低い点を除去 | **密度** | 層・正規化・距離関数で結果が激変 | 疎領域の検出 | 「珍しい」と「間違い」の区別不能 |
| **TDA異常検知** | Persistenceの異常を検出 | **位相** | 近傍閾値・埋め込みスケールで位相が変わる | トポロジーの破綻 | 高次元での計算困難 |
| **合成データ** | 論理エンジンで生成 | - | 生成ルールに依存 | 多様体の「設計」 | 分布の偏り、自己参照 |

### 測定空間に関する注意

> **同じ「距離」という語でも、空間が違えば意味が違う。**
> 本Appendixでは以後、必要に応じて「表現距離」「損失距離」のように空間名を冠する。

上表の「測定量」は、必ずしも **表現空間（埋め込み空間）** で測られているわけではない：

| 測定量 | 実際に測られている空間 | 表現空間との関係 |
| -------- | ---------------------- | ----------------- |
| **距離**（EL2Nなど） | 損失空間、予測分布空間 | 間接的（損失距離が小さい ≠ 表現距離が近い） |
| **曲率**（Influence Functions） | 損失のHessian近傍 | 多様体の曲率とは別物 |
| **密度**（kNN） | 表現空間だが、表現の取り方（層・正規化・距離関数）に敏感 | 座標系の選択で結果が変わる |
| **位相**（TDA） | 表現空間の近傍グラフ | 距離閾値の選択に依存 |

> [!CAUTION]
> 「EL2Nで損失距離が大きい」と「表現多様体から遠い」は同じではない。
> 各手法が「何の空間で何を測っているか」を常に確認すべきである。

### 観察

これらの手法は「幾何学的に正しい」から選んでいるのではなく、以下のいずれかに依存している：

- 統計的多数派（EL2N、kNN）
- 外部の論理（合成データ）
- 人間の判断（ラベリング）

## 幾何学的データ選別が実用困難な理由

### 原理的な識別不能性

次元の呪いや鶏と卵問題の前に、より根本的な制約がある：

| 幾何学が見るもの | 真偽判定に必要なもの |
| --------------- | -------------------- |
| **内在的性質**（距離・曲率・位相） | **外部参照**（世界知識・論理規則・観測事実） |

同じ幾何配置（同じ距離関係、同じ曲率、同じ位相）を持つ2つの表現空間があっても、一方では `1+1=2` が真、他方では `1+1=3` が真、というラベル付けは**幾何学的に区別できない**。

> 幾何学は「形」を測るが、「形に付与された意味」は測れない。
> 真偽判定には、幾何学の外にある構造（ツール、ルール、監督信号）が**原理的に必要**である。

この識別不能性があるからこそ、後述の"Tool Use"は「逃げ」ではなく「必然」となる。

### 次元の呪い（表現距離・密度・曲率すべてに影響）

| 測定量 | 低次元での挙動 | 高次元での挙動 |
| -------- | --------------- | --------------- |
| 表現距離 | 点間の差が明確 | 距離の集中（[第13回](13.md)参照） |
| 密度 | 局所密度推定が安定 | サンプル数が指数的に必要 |
| 曲率 | 二階微分が計算可能 | 推定誤差が爆発 |

> [!CAUTION]
> 「高次元だから必ず破綻する」わけではない（[第13回](13.md)の注意事項参照）。
> 内在次元が低い場合や、強い構造がある場合は緩和されうる。
> ただし、汎用的なデータ選別ツールとしては信頼性が不足している。

### 鶏と卵問題

曲率異常や位相異常を検出するには、まず「正しい多様体」が存在する必要がある。
しかし、その多様体自体が「ゴミデータを含んで学習されている」可能性がある。

```txt
正しい多様体 → 異常検出 → クリーンなデータ → 正しい多様体
     ↑                                           ↓
     └───────── 循環依存 ←────────────────────────┘
```

### 論理と幾何の断絶

**論理整合性の例：**
> 「A→B」かつ「B→C」ならば「A→C」（推移律）

これが埋め込み空間で以下のように対応する**保証がない**：

$$d(\mathbf{v}_A, \mathbf{v}_B) + d(\mathbf{v}_B, \mathbf{v}_C) \geq d(\mathbf{v}_A, \mathbf{v}_C)$$

三角不等式は常に成り立つ。しかし、**「含意の向き」**（A→BとB→Aは別物）や **「反例の存在」** （ $\exists x : \neg P(x)$ ）は、表現距離だけでは表現できない。

> 一般の一階述語論理の意味論まで含めると、距離制約だけで忠実に表すのは難しい（少なくとも自明ではない）。
> これが「論理と幾何の断絶」の意味である。

**事実整合性の例：**
> 「東京は日本の首都」が正しいかどうかは、埋め込み空間の幾何学だけでは判定できない。
> 外部の参照（世界知識）が必要。

> [!NOTE]
> TDAのBetti数は「穴の存在」を検出するが、それが「論理矛盾」である保証はない。
> 幾何学的な「穴」と論理的な「矛盾」の対応関係は、研究途上の仮説である。

## 確信した嘘（Confident Lies）: ハルシネーションの2類型

### 第7回との対比で見る純度問題の深刻さ

[第7回「不確実性の復権」](07.md)では、ハルシネーションを「不確実性の表出」として扱った。
しかし、本Appendixで問題とするハルシネーションは、それとは**本質的に異なる**。

**鍵となる違い：**
> 第7回は「**無知の捏造**」を扱った。
> 本Appendixは「**誤信念の表出**」を扱う。

この違いを見落とすと、「不確実性推定でハルシネーションは解決できる」という誤解に陥る。

### 幾何学的な2類型の対比

**定義（幾何学的観点から）：**

- **無知の捏造**：集中度 $\kappa$ が低い状態。分布が広がり、方向 $\mu$ の不確実性が高い。
- **誤信念の表出**：集中度 $\kappa$ は高いが、方向 $\mu$ が誤っている状態。確信を持って間違った方向を指す。

| 観点 | 第7回: 無知の捏造 | Appendix 2: 誤信念の表出 |
| ------ | ----------------- | ------------------------- |
| **メカニズム** | 知識の欠如から生じる曖昧な予測 | 訓練データの誤りから学習した確信 |
| **幾何学的状態** | 集中度 $\kappa$ が低い<br>星がない空白地帯で、無理やり星座を結んでいる | 集中度 $\kappa$ は高いが方向 $\mu$ が嘘<br>「1+1=3」という偽の星が、はっきりと刻まれている |
| **確率分布** | 分散が大きい（フラットな分布） | 分散が小さい（尖った分布） |
| **AIの心理** | 「自信はないが、確率的に一番ありそうなのはこれ」 | 「**自信を持って言うが**、1+1は3である（と習った）」 |
| **サンプリング温度の効果** | 温度を上げれば多様化（不確実性が顕在化） | 温度を上げても間違いの方向は変わらない |
| **対策の可否** | 閾値で切る、検索（RAG）で埋める | **幾何学単独では原理的に識別不能**<br>外部ツールによる検証が必要 |

### 球面上での可視化

**無知の捏造（第7回）：**

```txt
      .  .  .   ← サンプル群が広く散らばる
    .       .
  .   (mu?)  .   ← どこが中心か自信がない（低kappa）
    .       .
      .  .  .
```

**誤信念の表出（本Appendix）：**

```txt
                ← サンプルが一点に集中
                ← しかしその方向が間違っている
     ★★★       ← 集中度kappaは高い
    ★ ✗ ★      ← ✗ = 誤った答え
     ★★★       ← モデルは確信している
```

### 純度問題が深刻な理由

第7回の不確実性推定は「知らないことを知っている」状態を検出できる。
これは重要な進歩だが、**「間違って知っている」状態**には無力である。

**具体例：**

| 質問 | 第7回で検出可能なケース | Appendix 2で問題となるケース |
| ------ | ------------------------- | ---------------------------- |
| 「東京都の人口は？」 | 集中度が低い → 「わかりません」と答える | 「確信を持って5000万人です」（実際は約1400万人） |
| 「1+1は？」 | 集中度が低い → サンプリングで多様な答え | 「確信を持って3です」（訓練データに誤りがあった） |
| 「フランスの首都は？」 | 集中度が低い → 不確実性が表出 | 「確信を持ってロンドンです」（混同データを学習） |

**幾何学的診断の限界：**

```txt
第7回の手法：
- 集中度kappaを測定 → 低ければ警告 ✓ 有効

本Appendixの問題：
- 集中度kappaは高い（モデルは確信している）
- しかし方向muが間違っている
- 幾何学単独では「正しい方向」が不明 ✗ 識別不能
```

### なぜ幾何学単独では識別できないのか

「原理的な識別不能性」にて述べたように、幾何学は**内在的性質**（距離・曲率・位相）しか見ない。

2つの表現空間を考える：

**空間A:** `1+1=2` が真、全サンプルが高い集中度 $\kappa$ で正しい方向を指す
**空間B:** `1+1=3` が真、全サンプルが高い集中度 $\kappa$ で間違った方向を指す

この2つは、**幾何学的には区別不可能**である：

- 両方とも集中度 $\kappa$ は高い
- 両方とも球面上の単峰分布
- 距離関係、曲率、位相は同じ

**違いは「意味の付与」だけ**であり、それは幾何学の外にある。

### 動態論への伏線

> 「確信した嘘」は、学習時の静的な問題（純度）として現れるが、
> 推論時には **偽の極小値（shallow attractor）** として顕在化する。

**予告：**
続編「情報幾何学とAIの動態論」第8回では、Chain of Thoughtのエネルギー地形を扱う。
そこでは「浅い谷にトラップされる＝ハルシネーション」という診断を、動的システムの言葉で描写する。

本Appendixで述べた「誤信念の表出」は、動態論では次のように翻訳される：

| 静的（本Appendix） | 動的（続編） |
| ------------------- | -------------- |
| 誤った方向 $\mu$ に高い集中度 $\kappa$ | 偽の極小値（shallow local minimum） |
| データの純度問題 | エネルギー地形の汚染 |
| 幾何学単独では識別不可 | 軌道の追跡で部分的に診断可能？（研究中） |

> [!NOTE]
> 第7回の「無知の捏造」は **entropy-based detection** で対処できる。
> 本Appendixの「誤信念の表出」は **external verification** が必要。
> 動態論の「浅い谷」は **trajectory analysis** で診断を試みる。
>
> これら3つは、同じ「ハルシネーション」という現象の、異なる側面である。

## 将来の研究方向

### ～SF時代への地図（仮説レベル）～

成功の定義:

> 成功とは「混入率を下げる」ことではなく、「**影響度の高い誤りを減らす**」ことで評価する。
> 影響度 = そのサンプルを除去・重み変更したときの、検証誤差・整合性テスト・推論安定性の変化量。

以下の表の「成功指標」は、この定義に基づく。

| 方向 | アイデア | 測定量 | 成功指標 | 障壁 |
| ------ | --------- | -------- | --------- | ------ |
| 多様体上の異常検知 | 局所次元・曲率の急変を検出 | 曲率 | **性能**：除去後に検証誤差↓、推論安定性↑ | 高次元での推定精度 |
| 論理制約の埋め込み学習 | 推移律などを損失関数に組み込む | 表現距離 | **整合性**：推移律テスト集合での違反率↓ | 言語の曖昧さ、スケール |
| 自己矛盾の位相的検出 | Persistenceの異常から矛盾を推定 | 位相 | **整合性**：既知の矛盾例で特定パターンが再現 | 因果関係の不明確さ |
| 合成データによる多様体設計 | 「正しい」多様体を先に設計 | - | **整合性**：外挿領域での事実整合性↑ | 分布の網羅性、自食作用 |
| Tool Use（外部検証） | 計算・検索ツールで事実を検証 | - | **性能**：検証成功率・コスト・レイテンシのPareto改善 | 幾何学的手法ではない |

### 成功指標の分類

- **整合性ベンチ**：推移律違反率、矛盾テスト、事実検証成功率など（純度の「論理・事実整合性」に対応）
- **性能ベンチ**：一般タスク精度、ロバスト性、推論安定性など（純度の「影響度」に対応）

**現時点での誠実な結論：**
> 幾何学的なデータ選別は「理論的には美しい」が「汎用的な道具がない」。
> 当面は、外部の論理エンジン（Tool Use）や合成データに頼らざるを得ない。

## 動態論への接続

### 静的な問題と動的な問題の対応

| 観点 | 静的（本Appendix） | 動的（続編） |
| ------ | ------------- | ------------- |
| 主題 | 空間の形状 | 情報の流れ |
| データ品質の影響 | 配置の歪み | 速度場の乱流 |
| 異常の現れ方 | 地図の誤り | 偽の極小値、軌道のトラップ |
| 現状の対処 | 外部フィルタリング | 正則化、温度調整 |

### 動態論で扱うべき問い

> もし異常データが混入したまま学習されたとき、**推論時のダイナミクス**はどう破綻するか？
> それを「動的に」検出・修理できるか？

**予告：**
動態論 第8回（CoTのエネルギー地形）では、「浅い谷にトラップ＝幻覚」という診断を扱う。
これは、本Appendixで述べた「データ品質の問題」が、推論時に**偽の極小値**として顕在化する現象である。

> [!NOTE]
> 本Appendixは本講義の「静的な限界」を述べた。
> 動態論では「動的な破綻と修理」を扱う。
> 両方揃えて初めて、AIシステムの幾何学的健全性の全体像が見える。

## 参考文献

- Levina, E. & Bickel, P. J. (2004). Maximum Likelihood Estimation of Intrinsic Dimension. *NeurIPS*.
- Facco, E. et al. (2017). Estimating the intrinsic dimension of datasets by a minimal neighborhood information. *Scientific Reports*.
- Carlsson, G. (2009). Topology and Data. *Bulletin of the AMS*.
- Koh, P. W. & Liang, P. (2017). Understanding Black-box Predictions via Influence Functions. *ICML*.
- Paul, M. et al. (2021). Deep Learning on a Data Diet: Finding Important Examples Early in Training. *NeurIPS*. （EL2Nスコア）
