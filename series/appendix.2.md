
# Appendix 2: 多様体の純度問題: 幾何学がまだ解けていない課題

## 問題の所在

本編は「空間の形」を設計する言語を整えた。しかし、その空間に注ぎ込まれる**データの真偽**については、幾何学は沈黙している。

**問い：**
> 正規化や球面化によって「計算の形式」は安定した。
> では「データの内容」を幾何学的に選別できるか？

**結論を先取りすれば：**
> 現時点では**できない**。本Appendixはその理由と、将来の研究方向を地図として提示する。

**本Appendixにおける「純度」の定義：**
> 表現空間において、論理整合性・事実整合性に反するサンプルが、
> 学習分布にどれだけ**混入しているか**、および学習結果に**どれだけ影響を与えるか**。

- **混入率**：問題のあるサンプルの割合
- **影響度**：そのサンプル（またはクラスター）を除去・重み変更したときの、検証誤差・整合性テスト・推論安定性の変化量

混入率が低くても影響度が高い場合（例：頻出パターンに矛盾するデータ）、純度は低いと見なす。

## 本Appendixの射程

### 扱うこと

- 幾何学的安定化（表現空間の設計）と、データ選別（真偽判定）のギャップ
- 現行手法の幾何学的翻訳と、その限界
- 将来の研究方向（仮説レベル）

### 扱わないこと

- 特定アーキテクチャの批評（nGPT、GPT-4など）
- 社会制度論（誰がデータを管理すべきか）
- 最終的なアライメント論（何が「正しい」価値観か）

### 「正しさ」の3類型

本Appendixで「正しさ」という語を使う際、以下を区別する：

| 類型 | 定義 | 例 | 幾何学との関係 |
| ------ | ------ | ----- | --------------- |
| **論理整合性** | 推論規則に従っているか | A→B, B→C ならば A→C | 測地線の推移性？（未確立） |
| **事実整合性** | 観測・世界知識と一致するか | 1+1=2, 東京は日本の首都 | 外部参照が必要（幾何学単独では不可） |
| **規範整合性** | 価値判断として望ましいか | 公平性、安全性 | 幾何学の射程外 |

**注意：** 以下の議論は主に**論理整合性**と**事実整合性**に焦点を当てる。規範整合性は本質的に幾何学の外にある。

## 正規化が解決したこと・しなかったこと

[第3回「球面・正規化」](03.md)の限界について。

### 解決したこと（確立された効果）

| 問題 | 正規化による解決 | 幾何学的解釈 |
| ------ | ---------------- | ------------- |
| 学習の発散 | ノルムを一定に保つ | 球面上に拘束 |
| 収束の遅さ | 勾配のスケールが安定 | 曲率の均一化 |
| 表現の崩壊 | 方向のみで比較 | 角度空間への射影 |

### 解決しなかったこと（本質的な限界）

正規化は「ベクトルの方向」を揃えるが、「その方向が正しいか」は判断しない。

| 入力 | 正規化後 | 問題 |
| ------ | --------- | ------ |
| 「1+1=2」の埋め込み | 単位球面上の点 $\mathbf{v}_1$ | - |
| 「1+1=3」の埋め込み | 単位球面上の点 $\mathbf{v}_2$ | $\mathbf{v}_1$ と $\mathbf{v}_2$ の区別は**学習データの統計**に依存 |

**幾何学的に言えば：**
> 球面上に綺麗に配置されたデータが、全員「間違った方向」を指していても、モデルはそれを「正しい方向」として学習する。
> 正規化は「形式の安定」を与えるが、「内容の真偽」には中立である。

> [!NOTE]
> これは正規化の「欠陥」ではなく「設計上の射程」である。正規化に真偽判定を期待するのは、定規に善悪の判断を期待するようなものだ。

## 現行のデータ選別手法と幾何学的解釈

### 既存の道具を多様体の言葉で読み直す

| 手法 | 何をしているか | 測定量 | モデル依存性 | 幾何学的解釈 | 限界 |
| ------ | --------------- | -------- | ------------- | ------------- | ------ |
| **人手ラベリング** | 人間が「良い/悪い」を判定 | - | なし | 外部の神託 | スケールしない |
| **EL2Nスコア** | 予測誤差の大きいデータを選別 | **距離** | モデル・学習段階に依存 | 損失距離の代理 | 「難しい」と「間違い」の区別不能 |
| **Influence Functions** | 除去時の損失変化を逆算 | **曲率** | モデル・近似手法に依存 | Hessian近傍の寄与 | 計算コスト、近似の不安定さ |
| **kNN外れ値検出** | 近傍密度が低い点を除去 | **密度** | 層・正規化・距離関数で結果が激変 | 疎領域の検出 | 「珍しい」と「間違い」の区別不能 |
| **TDA異常検知** | Persistenceの異常を検出 | **位相** | 近傍閾値・埋め込みスケールで位相が変わる | トポロジーの破綻 | 高次元での計算困難 |
| **合成データ** | 論理エンジンで生成 | - | 生成ルールに依存 | 多様体の「設計」 | 分布の偏り、自己参照 |

### 測定空間に関する注意

> **同じ「距離」という語でも、空間が違えば意味が違う。**
> 本Appendixでは以後、必要に応じて「表現距離」「損失距離」のように空間名を冠する。

上表の「測定量」は、必ずしも**表現空間（埋め込み空間）**で測られているわけではない：

| 測定量 | 実際に測られている空間 | 表現空間との関係 |
| -------- | ---------------------- | ----------------- |
| **距離**（EL2Nなど） | 損失空間、予測分布空間 | 間接的（損失距離が小さい ≠ 表現距離が近い） |
| **曲率**（Influence Functions） | 損失のHessian近傍 | 多様体の曲率とは別物 |
| **密度**（kNN） | 表現空間だが、表現の取り方（層・正規化・距離関数）に敏感 | 座標系の選択で結果が変わる |
| **位相**（TDA） | 表現空間の近傍グラフ | 距離閾値の選択に依存 |

> [!CAUTION]
> 「EL2Nで損失距離が大きい」と「表現多様体から遠い」は同じではない。
> 各手法が「何の空間で何を測っているか」を常に確認すべきである。

### 観察

これらの手法は「幾何学的に正しい」から選んでいるのではなく、以下のいずれかに依存している：

- 統計的多数派（EL2N、kNN）
- 外部の論理（合成データ）
- 人間の判断（ラベリング）

## 幾何学的データ選別が実用困難な理由

### 0. 原理的な識別不能性

次元の呪いや鶏と卵問題の前に、より根本的な制約がある：

| 幾何学が見るもの | 真偽判定に必要なもの |
| --------------- | -------------------- |
| **内在的性質**（距離・曲率・位相） | **外部参照**（世界知識・論理規則・観測事実） |

同じ幾何配置（同じ距離関係、同じ曲率、同じ位相）を持つ2つの表現空間があっても、一方では `1+1=2` が真、他方では `1+1=3` が真、というラベル付けは**幾何学的に区別できない**。

> 幾何学は「形」を測るが、「形に付与された意味」は測れない。
> 真偽判定には、幾何学の外にある構造（ツール、ルール、監督信号）が**原理的に必要**である。

この識別不能性があるからこそ、後述の"Tool Use"は「逃げ」ではなく「必然」となる。

### 次元の呪い（表現距離・密度・曲率すべてに影響）

| 測定量 | 低次元での挙動 | 高次元での挙動 |
| -------- | --------------- | --------------- |
| 表現距離 | 点間の差が明確 | 距離の集中（[第13回](13.md)参照） |
| 密度 | 局所密度推定が安定 | サンプル数が指数的に必要 |
| 曲率 | 二階微分が計算可能 | 推定誤差が爆発 |

> [!CAUTION]
> 「高次元だから必ず破綻する」わけではない（[第13回](13.md)の注意事項参照）。
> 内在次元が低い場合や、強い構造がある場合は緩和されうる。
> ただし、汎用的なデータ選別ツールとしては信頼性が不足している。

### 鶏と卵問題

曲率異常や位相異常を検出するには、まず「正しい多様体」が存在する必要がある。
しかし、その多様体自体が「ゴミデータを含んで学習されている」可能性がある。

```txt
正しい多様体 → 異常検出 → クリーンなデータ → 正しい多様体
     ↑                                           ↓
     └───────── 循環依存 ←────────────────────────┘
```

### 論理と幾何の断絶

**論理整合性の例：**
> 「A→B」かつ「B→C」ならば「A→C」（推移律）

これが埋め込み空間で以下のように対応する**保証がない**：

$$d(\mathbf{v}_A, \mathbf{v}_B) + d(\mathbf{v}_B, \mathbf{v}_C) \geq d(\mathbf{v}_A, \mathbf{v}_C)$$

三角不等式は常に成り立つ。しかし、**「含意の向き」**（A→BとB→Aは別物）や **「反例の存在」** （ $\exists x : \neg P(x)$ ）は、表現距離だけでは表現できない。

> 一般の一階述語論理の意味論まで含めると、距離制約だけで忠実に表すのは難しい（少なくとも自明ではない）。
> これが「論理と幾何の断絶」の意味である。

**事実整合性の例：**
> 「東京は日本の首都」が正しいかどうかは、埋め込み空間の幾何学だけでは判定できない。
> 外部の参照（世界知識）が必要。

> [!NOTE]
> TDAのBetti数は「穴の存在」を検出するが、それが「論理矛盾」である保証はない。
> 幾何学的な「穴」と論理的な「矛盾」の対応関係は、研究途上の仮説である。

## 将来の研究方向

### ～SF時代への地図（仮説レベル）～

成功の定義:

> 成功とは「混入率を下げる」ことではなく、「**影響度の高い誤りを減らす**」ことで評価する。
> 影響度 = そのサンプルを除去・重み変更したときの、検証誤差・整合性テスト・推論安定性の変化量。

以下の表の「成功指標」は、この定義に基づく。

| 方向 | アイデア | 測定量 | 成功指標 | 障壁 |
| ------ | --------- | -------- | --------- | ------ |
| 多様体上の異常検知 | 局所次元・曲率の急変を検出 | 曲率 | **性能**：除去後に検証誤差↓、推論安定性↑ | 高次元での推定精度 |
| 論理制約の埋め込み学習 | 推移律などを損失関数に組み込む | 表現距離 | **整合性**：推移律テスト集合での違反率↓ | 言語の曖昧さ、スケール |
| 自己矛盾の位相的検出 | Persistenceの異常から矛盾を推定 | 位相 | **整合性**：既知の矛盾例で特定パターンが再現 | 因果関係の不明確さ |
| 合成データによる多様体設計 | 「正しい」多様体を先に設計 | - | **整合性**：外挿領域での事実整合性↑ | 分布の網羅性、自食作用 |
| Tool Use（外部検証） | 計算・検索ツールで事実を検証 | - | **性能**：検証成功率・コスト・レイテンシのPareto改善 | 幾何学的手法ではない |

### 成功指標の分類

- **整合性ベンチ**：推移律違反率、矛盾テスト、事実検証成功率など（純度の「論理・事実整合性」に対応）
- **性能ベンチ**：一般タスク精度、ロバスト性、推論安定性など（純度の「影響度」に対応）

**現時点での誠実な結論：**
> 幾何学的なデータ選別は「理論的には美しい」が「汎用的な道具がない」。
> 当面は、外部の論理エンジン（Tool Use）や合成データに頼らざるを得ない。

## 動態論への接続

### 静的な問題と動的な問題の対応

| 観点 | 本講義（静的） | 続講義（動的） |
| ------ | ------------- | ------------- |
| 主題 | 空間の形状 | 情報の流れ |
| データ品質の影響 | 配置の歪み | 速度場の乱流 |
| 異常の現れ方 | 地図の誤り | 偽の極小値、軌道のトラップ |
| 現状の対処 | 外部フィルタリング | 正則化、温度調整 |

### 動態論で扱うべき問い

> もし異常データが混入したまま学習されたとき、**推論時のダイナミクス**はどう破綻するか？
> それを「動的に」検出・修理できるか？

**予告：**
動態論 第8回（CoTのエネルギー地形）では、「浅い谷にトラップ＝幻覚」という診断を扱う。
これは、本Appendixで述べた「データ品質の問題」が、推論時に**偽の極小値**として顕在化する現象である。

> [!NOTE]
> 本Appendixは本講義の「静的な限界」を述べた。
> 動態論では「動的な破綻と修理」を扱う。
> 両方揃えて初めて、AIシステムの幾何学的健全性の全体像が見える。

## 参考文献

- Levina, E. & Bickel, P. J. (2004). Maximum Likelihood Estimation of Intrinsic Dimension. *NeurIPS*.
- Facco, E. et al. (2017). Estimating the intrinsic dimension of datasets by a minimal neighborhood information. *Scientific Reports*.
- Carlsson, G. (2009). Topology and Data. *Bulletin of the AMS*.
- Koh, P. W. & Liang, P. (2017). Understanding Black-box Predictions via Influence Functions. *ICML*.
- Paul, M. et al. (2021). Deep Learning on a Data Diet: Finding Important Examples Early in Training. *NeurIPS*. （EL2Nスコア）
